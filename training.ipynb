{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartyAnimal:\n",
    "    \n",
    "    def __init___(self, nam):\n",
    "        self.x = 0\n",
    "        self.name = nam\n",
    "        print(self.name,\"constructed\")\n",
    "    def party(self):\n",
    "        self.x = self.x + 1\n",
    "        print(self.name, \"party count\", self.x)\n",
    "\n",
    "class FootballFan(PartyAnimal):\n",
    "    def __init__(self, nam):\n",
    "        super().__init__(nam)\n",
    "        self.points = 0\n",
    "    def touchdown(self):\n",
    "        self.points = self.points + 7\n",
    "        self.party()\n",
    "        print(self.name, \"points\", self.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, y):\n",
    "        self.nameofmethod = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tweet(\"wow\")\n",
    "a.nameofmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cubes(n):\n",
    "    result = []\n",
    "    for x in range(n):\n",
    "        result.append(x**3)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in create_cubes(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_create_cubes(n):\n",
    "    for x in range(n):\n",
    "       yield x**3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in generator_create_cubes(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fibon(n):\n",
    "    a = 1\n",
    "    b = 1\n",
    "    for i in range(n):\n",
    "        yield a\n",
    "        a,b = b,a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in gen_fibon(10):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_generator():\n",
    "    for x in range(3):\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number in simple_generator():\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = simple_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter in s:\n",
    "    print(letter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_iter = iter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(s_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(s_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(s_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(s_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(name='Nuno'):\n",
    "    print('The hello() function has been executed!')\n",
    "    \n",
    "    def greet():\n",
    "        return '\\t This is the greet() func inside hello'\n",
    "    \n",
    "    def welcome():\n",
    "        return '\\t This is welcome() inside hello'\n",
    "    \n",
    "    print(greet())\n",
    "    print(welcome())\n",
    "    print('This is the end of the hello function!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello(name='Jose'):\n",
    "    print('The hello() function has been executed!')\n",
    "    \n",
    "    def greet():\n",
    "        return '\\t This is the greet() func inside hello'\n",
    "    \n",
    "    def welcome():\n",
    "        return '\\t This is the welcome() func inside hello'\n",
    "    \n",
    "    print('I am going to return a function!!')\n",
    "    if name == 'Nuno':\n",
    "        return greet\n",
    "    else:\n",
    "        return welcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_func = hello('Jose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_new_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cool():\n",
    "    def super_cool():\n",
    "        return 'I am very cool!'\n",
    "    return super_cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_func = cool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello():\n",
    "    return 'Hi Jose!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a function as an argument\n",
    "def other(some_def_func):\n",
    "    print('Other code runs here')\n",
    "    print(some_def_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have the tools to create a decorator\n",
    "\n",
    "def new_decorator(original_func):\n",
    "    def wrap_func():\n",
    "        \n",
    "        print('Some extra code, before the original function')\n",
    "        \n",
    "        original_func()\n",
    "        \n",
    "        print('Some extra code, after the original function!')\n",
    "        \n",
    "    return wrap_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_needs_decorator():\n",
    "    print(\"I want to be decorated!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_needs_decorator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_decorator(func_needs_decorator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "decorated_func = new_decorator(func_needs_decorator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decorated_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@new_decorator\n",
    "def func_needs_decorator():\n",
    "    print(\"I want to be decorated!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_needs_decorator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a generator that generates the squares of numbers up to some number N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_gen = (x**2 for x in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in square_gen:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a generator that yields \"n\" random numbers between a low and high number (that are inputs).\n",
    "#Note: Use the random library. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_gen(low, high, n):\n",
    "    for i in range(n):\n",
    "        yield random.randint(low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in rand_gen(1,10,12):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the iter() function to convert the tstring below into an iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"hello\"\n",
    "s = iter(s)\n",
    "print(next(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain a use case for a generator using a yield statement where you would not want to use a normal function statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the output takes too much memory and you dont want it all it makes sense to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [1,2,3,4,5]\n",
    "\n",
    "gencomp = (item for item in my_list if item > 3)\n",
    "\n",
    "for item in gencomp:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula for Angle Between Two Vectors\n",
    "\n",
    "$$\n",
    "\\text{To compute the angle } \\theta \\text{ between two vectors } \\mathbf{v1} \\text{ and } \\mathbf{v2}:\n",
    "\n",
    "\\theta = \\arccos\\left(\\frac{\\mathbf{v1} \\cdot \\mathbf{v2}}{\\|\\mathbf{v1}\\| \\cdot \\|\\mathbf{v2}\\|}\\right)\n",
    "\n",
    "\\text{where:}\n",
    "- \\mathbf{v1} \\cdot \\mathbf{v2} \\text{ denotes the dot product of vectors } \\mathbf{v1} \\text{ and } \\mathbf{v2},\n",
    "- \\|\\mathbf{v1}\\| \\text{ and } \\|\\mathbf{v2}\\| \\text{ represent the Euclidean norms (lengths) of vectors } \\mathbf{v1} \\text{ and } \\mathbf{v2}, \\text{ respectively.}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = 0.5 * v1\n",
    "np.arccos(v1.dot(v2) / (np.linalg.norm(v1) * (np.linalg.norm(v2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"Fit training data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like}, shape = [n_examples, n_features]\n",
    "    Training vectors, where n_examples is the number of\n",
    "    examples and n_features is the number of features.\n",
    "    y : array-like, shape = [n_examples]\n",
    "    Target values.\n",
    "    Returns\n",
    "    -------\n",
    "    self : object\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01,\n",
    "        size=X.shape[1])\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'https://archive.ics.uci.edu/ml/'\\\n",
    "    'machine-learning-databases/iris/iris.data'\n",
    "print('From URL:', s)\n",
    "df = pd.read_csv(s, header=None, encoding='utf-8')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "# plot data\n",
    "plt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label='Setosa')\n",
    "plt.scatter(X[50:100, 0], X[50:100, 1], color='blue', marker='s', label='Versicolor')\n",
    "plt.xlabel('Sepal length [cm]')\n",
    "plt.ylabel('Petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(eta=0.1, n_iter=10)\n",
    "ppn.fit(X, y)\n",
    "plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of updates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "# setup marker generator and color map\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0],\n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8,\n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx],\n",
    "                    label=f'Class {cl}',\n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X, y, classifier=ppn)\n",
    "plt.xlabel('Sepal length [cm]')\n",
    "plt.ylabel('Petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self_w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self_b_ = float(0.)\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = float(0.)\n",
    "        self.errors_=[]\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['name', 'quest', 'favorite color']\n",
    "answers = ['lancelot', 'the holy grail', 'blue']\n",
    "for q, a in zip(questions, answers):\n",
    "    print('What is your {0}?  It is {1}.'.format(q, a))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using lists as Stacks\n",
    "stack = [1, 2, 3, 4, 5]\n",
    "stack.append(6)\n",
    "stack.append(7)\n",
    "print(stack)\n",
    "stack.pop()\n",
    "print(stack)\n",
    "stack.pop()\n",
    "stack.pop()\n",
    "print(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "queue = deque([\"Eric\", \"John\", \"Michael\"])\n",
    "queue.append(\"Terry\")\n",
    "queue.append(\"Graham\")\n",
    "print(queue)\n",
    "queue.popleft()\n",
    "print(queue)\n",
    "queue.popleft()\n",
    "print(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Vector:\n",
    "    def __init__(self, x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __repr__(self):\n",
    "        return f'Vector({self.x!r}, {self.y!r})'\n",
    "    def __abs__(self):\n",
    "        return math.hypot(self.x, self.y)\n",
    "    def __bool__(self):\n",
    "        return bool(abs(self))\n",
    "    def __add__(self, other):\n",
    "        x = self.x + other.x\n",
    "        y = self.y + other.y\n",
    "        return Vector(x, y)\n",
    "    def __mul__(self, scalar):\n",
    "        return Vector(self.x * scalar, self.y * scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = Vector(1, 2)\n",
    "v2 = Vector(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = v1 + v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = float(0.)\n",
    "        self.errors_=[]\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = float(0.)\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "matrix_ = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(matrix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = float(0.)\n",
    "        self.errors_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaline Weight Update Rule Explanation\n",
    "\n",
    "The weight update rule in the Adaline Gradient Descent algorithm is based on the gradient of the Mean Squared Error (MSE) loss function.\n",
    "\n",
    "The MSE loss is given by:\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(N\\) is the number of samples,\n",
    "- \\(y_i\\) is the actual target value for the \\(i\\)-th sample,\n",
    "- \\(\\hat{y}_i\\) is the predicted value for the \\(i\\)-th sample.\n",
    "\n",
    "The gradient of the MSE with respect to the weights \\(w_j\\) is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_j} = \\frac{2}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i) \\cdot x_{ij}\n",
    "$$\n",
    "\n",
    "In matrix form, this can be written as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{2}{N} X^T \\cdot (y - \\hat{y})\n",
    "$$\n",
    "\n",
    "where \\(X\\) is the matrix of input features, \\(X^T\\) is its transpose, \\(y\\) is the vector of target values, and \\(\\hat{y}\\) is the vector of predicted values.\n",
    "\n",
    "The weights are updated using the gradient descent rule:\n",
    "\n",
    "$$\n",
    "w = w + \\eta \\cdot \\left( \\frac{\\partial L}{\\partial w} \\right)\n",
    "$$\n",
    "\n",
    "Expanding this, we get:\n",
    "\n",
    "$$\n",
    "w = w + \\eta \\cdot \\frac{2}{N} X^T \\cdot (y - \\hat{y})\n",
    "$$\n",
    "\n",
    "In the code, this is implemented as:\n",
    "\n",
    "```python\n",
    "self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    s = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    print('From URL:', s)\n",
    "    df = pd.read_csv(s,\n",
    "                     header=None,\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "except HTTPError:\n",
    "    s = 'iris.data'\n",
    "    print('From local Iris path:', s)\n",
    "    df = pd.read_csv(s,\n",
    "                     header=None,\n",
    "                     encoding='utf-8')\n",
    "    \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# select setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)\n",
    "\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:50, 0], X[:50, 1],\n",
    "            color='red', marker='o', label='Setosa')\n",
    "plt.scatter(X[50:100, 0], X[50:100, 1],\n",
    "            color='blue', marker='s', label='Versicolor')\n",
    "\n",
    "plt.xlabel('Sepal length [cm]')\n",
    "plt.ylabel('Petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# plt.savefig('images/02_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=f'Class {cl}', \n",
    "                    edgecolor='black')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Adaline in Python\n",
    "class AdalineGD:\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "    Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "    Passes over the training dataset.\n",
    "    random_state : int\n",
    "    Random number generator seed for random weight initialization.\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "    Weights after fitting.\n",
    "    b_ : Scalar\n",
    "    Bias unit after fitting.\n",
    "    losses_ : list\n",
    "    Mean squared error loss function values in each epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "            \n",
    "            Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "            Training vectors, where n_examples\n",
    "            is the number of examples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "            Target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = float(0.)\n",
    "        self.losses_ = []\n",
    "        for _ in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * 2.0 * errors.mean()\n",
    "            loss = (errors**2).mean()\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "ada1 = AdalineGD(n_iter=15, eta=0.1).fit(X, y)\n",
    "ax[0].plot(range(1, len(ada1.losses_) + 1), np.log10(ada1.losses_), marker='o')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('log(Mean squared error)')\n",
    "ax[0].set_title('Adaline - Learning rate 0.1')\n",
    "ada2 = AdalineGD(n_iter=15, eta=0.0001).fit(X, y)\n",
    "ax[1].plot(range(1, len(ada2.losses_) + 1), ada2.losses_, marker='o')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Mean squared error')\n",
    "ax[1].set_title('Adaline - Learning rate 0.0001')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "X_std = np.copy(X)\n",
    "X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()\n",
    "X_std[:, 1] = (X[:, 1] - X[:, 1].mean()) / X[:, 1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_gd = AdalineGD(n_iter=20, eta=0.5)\n",
    "ada_gd.fit(X_std, y)\n",
    "\n",
    "plot_decision_regions(X_std, y, classifier=ada_gd)\n",
    "plt.title('Adaline - Gradient descent')\n",
    "plt.xlabel('Sepal length [standardized]')\n",
    "plt.ylabel('Petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/02_14_1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(ada_gd.losses_) + 1), ada_gd.losses_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean squared error')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/02_14_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 2D array\n",
    "array_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Use ravel() to flatten the array\n",
    "flattened_array = array_2d.ravel()\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(array_2d)\n",
    "print(\"Flattened array:\")\n",
    "print(flattened_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGD:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state     \n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = float(0.)\n",
    "        self.losses_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * 2.0 * errors.mean()\n",
    "            losses = (errors**2).mean()\n",
    "            self.losses_.append(losses)\n",
    "        return self\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "    def activation(self, X):\n",
    "        return X\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "z = np.arange(-7, 7, 0.1)\n",
    "sigma_z = sigmoid(z)\n",
    "plt.plot(z, sigma_z)\n",
    "plt.axvline(0.0, color='k')\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma (z)$')\n",
    "# y axis ticks and gridline\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "ax = plt.gca()\n",
    "ax.yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_1(z):\n",
    "    return - np.log(sigmoid(z))\n",
    "def loss_0(z):\n",
    "    return - np.log(1 - sigmoid(z))\n",
    "z = np.arange(-10, 10, 0.1)\n",
    "sigma_z = sigmoid(z)\n",
    "c1 = [loss_1(x) for x in z]\n",
    "plt.plot(sigma_z, c1, label='L(w, b) if y=1')\n",
    "c0 = [loss_0(x) for x in z]\n",
    "plt.plot(sigma_z, c0, linestyle='--', label='L(w, b) if y=0')\n",
    "plt.ylim(0.0, 5.1)\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel('$\\sigma(z)$')\n",
    "plt.ylabel('L(w, b)')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGD:\n",
    "    \"\"\"Gradient descent-based logistic regression classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after training.\n",
    "    b_ : Scalar\n",
    "      Bias unit after fitting.\n",
    "    losses_ : list\n",
    "      Mean squared error loss function values in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : Instance of LogisticRegressionGD\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.losses_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * errors.mean()\n",
    "            loss = -y.dot(np.log(output)) - ((1 - y).dot(np.log(1 - output))) / X.shape[0]\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def activation(self, z):\n",
    "        \"\"\"Compute logistic sigmoid activation\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Gradient Descent\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "In logistic regression, the loss function used is the binary cross-entropy loss, also known as the log-loss. The loss function for \\(n\\) samples is given by:\n",
    "\n",
    "$$\n",
    "L(\\boldsymbol{w}, b) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "  (\\hat{y}^{(i)} = \\sigma(z^{(i)}) = \\frac{1}{1 + e^{-z^{(i)}}}) \\quad \\text{is the predicted probability using the sigmoid activation function.}\n",
    "$$\n",
    "$$\n",
    "  (z^{(i)} = \\boldsymbol{w}^T \\boldsymbol{x}^{(i)} + b) \\quad \\text{is the linear combination of the input features and weights.}\n",
    "$$\n",
    "### Gradient of the Loss Function\n",
    "\n",
    "To minimize this loss function using gradient descent, we need to compute its gradient with respect to the weights \\(\\boldsymbol{w}\\) and the bias \\(b\\).\n",
    "\n",
    "#### Gradient with respect to weights \\(\\boldsymbol{w}\\):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{w}} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\hat{y}^{(i)} - y^{(i)} \\right) \\boldsymbol{x}^{(i)}\n",
    "$$\n",
    "\n",
    "#### Gradient with respect to bias \\(b\\):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\hat{y}^{(i)} - y^{(i)} \\right)\n",
    "$$\n",
    "\n",
    "### Weight Updates\n",
    "\n",
    "Using gradient descent, we update the weights and bias as follows:\n",
    "\n",
    "#### For weights \\(\\boldsymbol{w}\\):\n",
    "\n",
    "$$\n",
    "\\boldsymbol{w} \\leftarrow \\boldsymbol{w} - \\eta \\frac{\\partial L}{\\partial \\boldsymbol{w}}\n",
    "$$\n",
    "\n",
    "Substituting the gradient, we get:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{w} \\leftarrow \\boldsymbol{w} - \\eta \\left( \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}^{(i)} - y^{(i)}) \\boldsymbol{x}^{(i)} \\right)\n",
    "$$\n",
    "\n",
    "#### For bias \\(b\\):\n",
    "\n",
    "$$\n",
    "b \\leftarrow b - \\eta \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "Substituting the gradient, we get:\n",
    "\n",
    "$$\n",
    "b \\leftarrow b - \\eta \\left( \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}^{(i)} - y^{(i)}) \\right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=f'Class {cl}', \n",
    "                    edgecolor='black')\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='none',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGD:\n",
    "     def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "     def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float_(0.)\n",
    "        self.losses_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * errors.mean()\n",
    "            loss = -y.dot(np.log(output)) - ((1 - y).dot(np.log(1 - output))) / X.shape[0]\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "     def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "     def activation(self, z):\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "     def predict(self, X):\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_01_subset = X_train_std[(y_train == 0) | (y_train == 1)]\n",
    "y_train_01_subset = y_train[(y_train == 0) | (y_train == 1)]\n",
    "lrgd = LogisticRegressionGD(eta=0.3, n_iter=1000, random_state=1)\n",
    "lrgd.fit(X_train_01_subset, y_train_01_subset)\n",
    "plot_decision_regions(X=X_train_01_subset, y=y_train_01_subset, classifier=lrgd)\n",
    "plt.xlabel('Petal length [standardized]')\n",
    "plt.ylabel('Petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/03_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "    markers = ('o','s','^','v','<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array(xx1.ravel(), xx2.ravel()).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.xlim(xx2.min(), xx2.max())\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=colors[idx], marker=markers[idx], label=f'Class {cl}', edgecolor='black')\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1], c='none', edgecolor='black', alpha=1.0, linewidth=1, marker='o', s=100, label='Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "csv_data = \\\n",
    "    '''A,B,C,D\n",
    "    1.0,2.0,3.0,4.0\n",
    "    5.0,6.0,,8.0\n",
    "    10.0,11.0,12.0,'''\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR stands for Interquartile Range. It is a measure of statistical dispersion, which is the spread of a data set. The IQR is calculated as the difference between the third quartile ($Q3$) and the first quartile ($Q1$):\n",
    "\n",
    "$ \\text{IQR} = Q3 - Q1 $\n",
    "\n",
    "Here's a brief explanation of the terms involved:\n",
    "\n",
    "- **First Quartile (Q1)**: This is the median of the lower half of the data set. It represents the 25th percentile, meaning 25% of the data points are below this value.\n",
    "- **Third Quartile (Q3)**: This is the median of the upper half of the data set. It represents the 75th percentile, meaning 75% of the data points are below this value.\n",
    "\n",
    "The IQR is useful for identifying outliers. Data points that lie below $Q1 - 1.5 \\times \\text{IQR}$ or above $Q3 + 1.5 \\times \\text{IQR}$ are often considered outliers. This method is particularly robust to the presence of outliers in the data, as it focuses on the middle 50% of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    ['green', 'M', 10.1, 'class2'],\n",
    "    ['red', 'L', 13.5, 'class1'],\n",
    "    ['blue', 'XL', 15.3, 'class2']\n",
    "    ])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_mapping = {'XL': 3, 'L':2, 'M':1}\n",
    "\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_size_mapping = {v: k for k, v in size_mapping.items()}\n",
    "df['size'].map(inv_size_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(df['classlabel']))}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classlabel'] = df['classlabel'].map(class_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "df['classlabel'] = df['classlabel'].map(inv_class_mapping)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df['classlabel'].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['color', 'size', 'price']].values\n",
    "color_le = LabelEncoder()\n",
    "X[:, 0] = color_le.fit_transform(X[:, 0])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = df[['color','size','price']].values\n",
    "color_ohe = OneHotEncoder()\n",
    "color_ohe.fit_transform(X[:, 0].reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "X = df[['color', 'size', 'price']].values\n",
    "c_transf = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(), [0]),\n",
    "    ('nothing', 'passthrough', [1, 2])\n",
    "])\n",
    "c_transf.fit_transform(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[['price', 'color', 'size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[['price', 'color', 'size']], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_ohe = OneHotEncoder(categories='auto', drop='first')\n",
    "c_transf = ColumnTransformer([\n",
    "    ('onehot', color_ohe, [0]),\n",
    "    ('nothing', 'passthrough', [1, 2])\n",
    "])\n",
    "c_transf.fit_transform(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['green', 'M', 10.1, 'class2'], \n",
    "['red', 'L', 13.5, 'class1'],\n",
    "['blue', 'XL', 15.3, 'class2']])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x > M'] = df['size'].apply(lambda x: 1 if x in {'L', 'XL'} else 0)\n",
    "df['x > L'] = df['size'].apply(lambda x: 1 if x == 'XL' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['size']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('./ch04/wine.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.columns = ['Class label', 'Alcohol',\n",
    "                   'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium',\n",
    "                   'Total phenols', 'Flavanoids',\n",
    "                   'Nonflavanoid phenols',\n",
    "                   'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue',\n",
    "                   'OD280/OD315 of diluted wines',\n",
    "                   'Proline']\n",
    "print('Class labels', np.unique(df_wine['Class label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = np.array([0, 1, 2, 3, 4, 5])\n",
    "print('standardized:', (ex - ex.mean()) / ex.std())\n",
    "print('normalized:', (ex - ex.min()) / (ex.max() - ex.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "lr = OneVsRestClassifier(LogisticRegression(penalty='l1', C=1.0, solver='liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegression(penalty='l1', C=1.0, solver='liblinear'))\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In scikit-learn, intercept_ corresponds to the bias unit\n",
    "for idx, classifier in enumerate(lr.estimators_):\n",
    "    print(f'Intercept for class {idx + 1}: {classifier.intercept_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In scikit-learn, coef_ corresponds to the values wj.\n",
    "for idx, classifier in enumerate(lr.estimators_):\n",
    "    print(f'Weight array for class {idx + 1}: {classifier.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Initialize the plot\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', \n",
    "          'black', 'pink', 'lightgreen', 'lightblue', 'gray', \n",
    "          'indigo', 'orange']\n",
    "weights, params = [], []\n",
    "\n",
    "# Iterate over different values of the regularization parameter C\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = OneVsRestClassifier(LogisticRegression(penalty='l1', \n",
    "                                                C=10.**c, \n",
    "                                                solver='liblinear', \n",
    "                                                random_state=0))\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    # Extract the weights for each binary classifier\n",
    "    # Since there are multiple classifiers, you might want to choose one specific class\n",
    "    weights.append(lr.estimators_[1].coef_[0])  # Access the second classifier's coefficients\n",
    "    params.append(10**c)\n",
    "\n",
    "# Convert weights list to a NumPy array\n",
    "weights = np.array(weights)\n",
    "\n",
    "# Plot each feature's weight coefficient against C\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column], label=df_wine.columns[column + 1], color=color)\n",
    "\n",
    "# Configure plot details\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('Weight coefficient')\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',\n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Initialize the plot with 3 subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))  # 3 rows, 1 column\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', \n",
    "          'black', 'pink', 'lightgreen', 'lightblue', 'gray', \n",
    "          'indigo', 'orange']\n",
    "weights, params = [], []\n",
    "\n",
    "# Iterate over different values of the regularization parameter C\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = OneVsRestClassifier(LogisticRegression(penalty='l1', \n",
    "                                                C=10.**c, \n",
    "                                                solver='liblinear', \n",
    "                                                random_state=0))\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Extract the weights for each binary classifier\n",
    "    for idx, classifier in enumerate(lr.estimators_):\n",
    "        if len(weights) <= idx:\n",
    "            weights.append([])  # Initialize a list for each classifier's weights\n",
    "        \n",
    "        weights[idx].append(classifier.coef_[0])  # Store coefficients for each classifier\n",
    "    \n",
    "    params.append(10**c)\n",
    "\n",
    "# Convert weights list to a NumPy array for easier manipulation\n",
    "weights = [np.array(w) for w in weights]\n",
    "\n",
    "# Plot each classifier's weight coefficients on a separate subplot\n",
    "for class_idx, (class_weights, ax) in enumerate(zip(weights, axes)):\n",
    "    for column, color in zip(range(class_weights.shape[1]), colors):\n",
    "        ax.plot(params, class_weights[:, column], \n",
    "                 label=df_wine.columns[column + 1], \n",
    "                 color=color)\n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim([10**(-5), 10**5])\n",
    "    ax.set_ylabel('Weight coefficient')\n",
    "    ax.set_title(f'Classifier for Class {class_idx + 1}')\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fancybox=True)\n",
    "\n",
    "# Set common labels\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.tight_layout(rect=[0, 0, 0.75, 1])  # Adjust the layout to fit the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.estimators_[0].coef_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#SBS means sequential backward selection and its an algorithm used for sequential feature selection, which aims to reduce the dimensionality \n",
    "#of the initial feature subspace\n",
    "class SBS:\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score, test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "            for p in combinations(self.indices_, r=dim -1):\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 = list(sbs.subsets_[10])\n",
    "print(df_wine.columns[1:][k3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std[:, k3], y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std[:, k3], y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std[:, k3], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = df_wine.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n",
    "plt.title('Feature importance'),\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align='center'),\n",
    "plt.xticks(range(X_train.shape[1]), feat_labels[indices], rotation=90),\n",
    "plt.xlim([-1, X_train.shape[1]]),\n",
    "plt.tight_layout(),\n",
    "plt.show()\n",
    "                            \n",
    "                            \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_wine = pd.read_csv('./ch05/wine.data', header=None)\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue',\n",
    "                   'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(X, y, test_size=0.3,\n",
    "                       stratify=y,\n",
    "                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "print('\\nEigenvalues \\n', eigen_vals)\n",
    "print('\\nEigenvectors \\n', eigen_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(1, 14), var_exp, align='center',\n",
    "        label='Individual explained variance')\n",
    "plt.step(range(1, 14), cum_var_exp, where='mid',\n",
    "         label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_02.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "               for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "               eigen_pairs[1][1][:, np.newaxis]))\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std[0].dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = X_train_std.dot(w)\n",
    "colors = ['r', 'b', 'g']\n",
    "markers = ['o', 's', '^']\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[y_train == l, 0], \n",
    "                X_train_pca[y_train == l, 1], \n",
    "                c=c, label=f'Class {l}', marker=m)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1, 14), pca.explained_variance_ratio_, align='center')\n",
    "plt.step(range(1, 14), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=f'Class {cl}', \n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "\n",
    "lr = OneVsRestClassifier(LogisticRegression(random_state=1, solver='lbfgs'))\n",
    "lr = lr.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_train_pca, y_train, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_04.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X_test_pca, y_test, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/05_05.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=None)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = eigen_vecs * np.sqrt(eigen_vals)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(range(13), loadings[:, 0], align='center')\n",
    "ax.set_ylabel('Loadings for PC 1')\n",
    "ax.set_xticks(range(13))\n",
    "ax.set_xticklabels(df_wine.columns[1:], rotation=90)\n",
    "\n",
    "plt.ylim([-1, 1])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('05_05_02.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(range(13), sklearn_loadings[:, 0], align='center')\n",
    "ax.set_ylabel('Loadings for PC 1')\n",
    "ax.set_xticks(range(13))\n",
    "ax.set_xticklabels(df_wine.columns[1:], rotation=90)\n",
    "\n",
    "plt.ylim([-1, 1])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('05_05_03.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "\n",
    "mean_vecs = []\n",
    "for label in range(1, 4):\n",
    "    mean_vecs.append(np.mean(X_train_std[y_train == label], axis=0))\n",
    "    print(f'MV {label}: {mean_vecs[label - 1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 13 # number of features\n",
    "S_W = np.zeros((d, d))\n",
    "for label, mv in zip(range(1, 4), mean_vecs):\n",
    "    class_scatter = np.zeros((d, d))  # scatter matrix for each class\n",
    "    for row in X_train_std[y_train == label]:\n",
    "        row, mv = row.reshape(d, 1), mv.reshape(d, 1)  # make column vectors\n",
    "        class_scatter += (row - mv).dot((row - mv).T)\n",
    "    S_W += class_scatter                          # sum class scatter matrices\n",
    "\n",
    "print('Within-class scatter matrix: '\n",
    "      f'{S_W.shape[0]}x{S_W.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class label distribution:',  \n",
    "      np.bincount(y_train)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 13  # number of features\n",
    "S_W = np.zeros((d, d))\n",
    "for label, mv in zip(range(1, 4), mean_vecs):\n",
    "    class_scatter = np.cov(X_train_std[y_train == label].T)\n",
    "    S_W += class_scatter\n",
    "    \n",
    "print('Scaled within-class scatter matrix: '\n",
    "      f'{S_W.shape[0]}x{S_W.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_overall = np.mean(X_train_std, axis=0)\n",
    "mean_overall = mean_overall.reshape(d, 1)  # make column vector\n",
    "\n",
    "d = 13  # number of features\n",
    "S_B = np.zeros((d, d))\n",
    "\n",
    "for i, mean_vec in enumerate(mean_vecs):\n",
    "    n = X_train_std[y_train == i + 1, :].shape[0]\n",
    "    mean_vec = mean_vec.reshape(d, 1)  # make column vector\n",
    "    S_B += n * (mean_vec - mean_overall).dot((mean_vec - mean_overall).T)\n",
    "\n",
    "print('Between-class scatter matrix: '\n",
    "      f'{S_B.shape[0]}x{S_B.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vecs[:, i])\n",
    "               for i in range(len(eigen_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eigen_pairs = sorted(eigen_pairs, key=lambda k: k[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "\n",
    "print('Eigenvalues in descending order:\\n')\n",
    "for eigen_val in eigen_pairs:\n",
    "    print(eigen_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# This ensures plots are displayed inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# Create a figure with 1 row and 3 columns\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "# Plot a line on the first subplot\n",
    "ax[0].plot(x, np.sin(x))\n",
    "ax[0].set_title('Line Plot')\n",
    "\n",
    "# Plot a scatter plot on the second subplot\n",
    "ax[1].scatter(x, np.sin(x), color='red')\n",
    "ax[1].set_title('Scatter Plot')\n",
    "\n",
    "# Plot a bar plot on the third subplot\n",
    "ax[2].bar([1, 2, 3], [3, 1, 2])\n",
    "ax[2].set_title('Bar Plot')\n",
    "\n",
    "# Show the plots\n",
    "plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X = np.linspace(0, 2*np.pi)\n",
    "Y = np.sin(X)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"O monitor é extra grande 000 afaa\"\n",
    "# Escreve uma função que detecte o numero de palavras validas numa 'string'.\n",
    "# Para ser valida a 'string' deverá ter 3 vogais, pelo menos uma consuante e cada palavra valida deverá ter no minimo comprimento de 3 caractéres. Cada 'string' tem de ser alfanumerica.\n",
    "# A função deverá retornar o número de palavras validas na 'string'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_(s:str):\n",
    "    valid_counter = 0\n",
    "    for p in s.split():\n",
    "        v_count = 0\n",
    "        c_count = 0\n",
    "        if len(p) >= 3 and p.isalnum() is True:\n",
    "            v = ['a','e','i','o','u']\n",
    "            for c in p:\n",
    "                if c in v:\n",
    "                    v_count += 1\n",
    "                if c not in v and type(c) != int:   \n",
    "                    c_count += 1\n",
    "            if v_count >= 3 and c_count > 0:\n",
    "                valid_counter += 1\n",
    "    return valid_counter\n",
    "           \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "         \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(string_(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_words(s: str) -> int:\n",
    "    vowels = set('aeiou')\n",
    "    valid_counter = 0\n",
    "\n",
    "    for p in s.split():\n",
    "        if len(p) < 3 or not p.isalnum():\n",
    "            continue  # Skip if the word is too short or not alphanumeric\n",
    "        \n",
    "        v_count = sum(1 for c in p if c in vowels)\n",
    "        c_count = sum(1 for c in p if c.isalpha() and c not in vowels)\n",
    "\n",
    "        if v_count >= 3 and c_count > 0:\n",
    "            valid_counter += 1\n",
    "\n",
    "    return valid_counter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
